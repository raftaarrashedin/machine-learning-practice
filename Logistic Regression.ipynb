{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwUbf0OvUvB0CAQEjS2+Rr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"g4akKlvhU0Qs","executionInfo":{"status":"error","timestamp":1678031585590,"user_tz":-330,"elapsed":634,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"1dd09038-e8f8-425c-e84a-25fc7361d7dd"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d8c697c63223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'LogisticRegression' from 'sklearn' (/usr/local/lib/python3.8/dist-packages/sklearn/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","from sklearn import LogisticRegression"]},{"cell_type":"code","source":["# Now we will define our Logistic Regression class and define construct method in it, In the construct method, we initialize our hyperparameters such as Learning rate, num iterations, and verbose\n","class LogisticRegression :\n","  def __init__(self,learning_rate = 0.01, num_iterations = 1000, verbose = False) :\n","    self.learning_rate = learning_rate\n","    self.num_iterations = num_iterations\n","    self.verbose = verbose"],"metadata":{"id":"jhJKJrtqVJRB","executionInfo":{"status":"ok","timestamp":1678029390483,"user_tz":-330,"elapsed":6,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# The SIGMOID function is a key function used in Logistic Regression. It maps any input value to a value betweeen 0 and 1. We define this function as a method in our class.\n","def sigmoid(self,z):\n","  return 1 / (1+np.exp(-z)) "],"metadata":{"id":"6RlWUSUPWHvV","executionInfo":{"status":"ok","timestamp":1678029532188,"user_tz":-330,"elapsed":6,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# The fit method where we implement the gradient descent algorithm to find the optimal weights that minimize our cost function. We first add a bias term to our input data X to make sure our predictions are not biased towards any particulture feature. We then initialize our weights to zeros. We then perform the gradient descent algorithm by iterating over the specified number of iteration. We calculate our predictions using the sigmoid function, calculate the error, and update our weights using the gradient of the cost function.\n","# If verbose is true, we print the cost at every 100 iteration.\n","\n","def fit(self,x,y) :\n","  # Add bias term to X\n","  X = np.insert(X,0,1,axis = 1)\n","\n","  # Initialize weights with zeros\n","  self.weights = np.zeros(X.shape[1])\n","\n","  # Gradient Descent \n","  for i in range(self.num_iterations) :\n","\n","    # Make predictions\n","    y_hat = self.sigmoid(np.dot(X, self.weights))\n","\n","    # Calculate error\n","    error = y_hat - y\n","\n","    # Update weights\n","    self.weights -= self.learning_rate * np.dot(X.T,error)\n","\n","    # Print progress\n","    if self.verbose and i % 100 == 0:\n","      print(f\"Iteration {i} : Cost = {self.cost(X,y)}\")\n","      "],"metadata":{"id":"9dPacuElWqc2","executionInfo":{"status":"ok","timestamp":1678030532355,"user_tz":-330,"elapsed":6,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# We then round the prediction to 0 and 1\n","def predict(self,x):\n","\n","  # Add bias term to X\n","  X = np.insert(X,0,1, axis = 1)\n","\n","  # Make Predictions\n","  y_hat = self.sigmoid(np.dot(X, self.weights))\n","\n","  # Round predictions to 0 and 1\n","  return np.round(y_hat)"],"metadata":{"id":"8uhn_fGBaemY","executionInfo":{"status":"ok","timestamp":1678030757275,"user_tz":-330,"elapsed":543,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# The cost method calculates the cost of our model using the cross-entropy loss function. We calculate the predictions using the sigmoid function and then calculate the cost using the formula for cross-entropy loss.\n","def cost(self,X,y) :\n","  \n","  # calculate cost\n","  y_hat = self.sigmoid(np.dot(X, self.weights))\n","  cost = -np.mean(y * np.log(y_hat) + (1-y) * np.log(1 - y_hat))\n","\n","  return cost"],"metadata":{"id":"Yb_QSsuXbVg2","executionInfo":{"status":"ok","timestamp":1678031199029,"user_tz":-330,"elapsed":6,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Generate some sample data\n","np.random.seed(0)\n","X = np.random.randn(100,2)\n","y = np.random.randint(0,2,size = 100)\n"],"metadata":{"id":"y_cwi7m2dBeN","executionInfo":{"status":"ok","timestamp":1678031335887,"user_tz":-330,"elapsed":4,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# We then create a LogisticRegression object and call the fit method with the generated data to train our model. We set learning_rate to 0.1 and num_iterations to 1000. We also set verbose to True to print the cost at every 100 iterations.\n","# Create a logistic Regression model and fit the data\n","model = LogisticRegression(learning_rate=0.1, num_iterations=1000, verbose=True)\n","model.fit(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"pSaaPxNwdiuj","executionInfo":{"status":"error","timestamp":1678031457135,"user_tz":-330,"elapsed":7,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"8951bce3-8026-45bb-8cc5-15cd1bb8c832"},"execution_count":9,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-72eef4166a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create a logistic Regression model and fit the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'fit'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"H8TxnciSd4Oa"},"execution_count":null,"outputs":[]}]}