{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPF/SXmP7oTI3Rpgy4ociqe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EcLeq0yOqOA","executionInfo":{"status":"ok","timestamp":1687502365649,"user_tz":-330,"elapsed":1216462,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"acf579bd-bcbe-445a-c065-25eb10c47326"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","620/620 [==============================] - 127s 201ms/step - loss: 0.6700 - accuracy: 0.7734\n","Epoch 2/10\n","620/620 [==============================] - 120s 194ms/step - loss: 0.6637 - accuracy: 0.7746\n","Epoch 3/10\n","620/620 [==============================] - 120s 194ms/step - loss: 0.6632 - accuracy: 0.7746\n","Epoch 4/10\n","620/620 [==============================] - 123s 199ms/step - loss: 0.6631 - accuracy: 0.7746\n","Epoch 5/10\n","620/620 [==============================] - 118s 191ms/step - loss: 0.6630 - accuracy: 0.7746\n","Epoch 6/10\n","620/620 [==============================] - 120s 194ms/step - loss: 0.6625 - accuracy: 0.7746\n","Epoch 7/10\n","620/620 [==============================] - 122s 196ms/step - loss: 0.6626 - accuracy: 0.7746\n","Epoch 8/10\n","620/620 [==============================] - 122s 196ms/step - loss: 0.6625 - accuracy: 0.7746\n","Epoch 9/10\n","620/620 [==============================] - 120s 193ms/step - loss: 0.6624 - accuracy: 0.7746\n","Epoch 10/10\n","620/620 [==============================] - 121s 195ms/step - loss: 0.6621 - accuracy: 0.7746\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa467271780>"]},"metadata":{},"execution_count":26}],"source":["import pandas as pd\n","import nltk\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","import re\n","\n","# Load the dataset\n","data = pd.read_csv('/content/Hate Speech Detection in Arabic Urdu -  labeled_data.csv.csv')\n","\n","# Preprocess the text\n","def preprocess(text):\n","    # Apply any necessary preprocessing steps such as removing special characters, normalization, etc.\n","    urdu_words_only = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n","    return urdu_words_only.strip()\n","\n","data['Tweet'] = data['Tweet'].apply(preprocess)\n","\n","data[\"Labels\"] = data[\"Class\"].map({0:\"Hate Speech\", 1:\"Offensive Language\", 2:\"No hate and Offensive Speech\"})\n","\n","# Split the data into training and test sets\n","X = data['Tweet']\n","y = data['Labels']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Tokenize the text\n","tokenizer = nltk.tokenize.WordPunctTokenizer()\n","X_train_tokens = [tokenizer.tokenize(text) for text in X_train]\n","X_test_tokens = [tokenizer.tokenize(text) for text in X_test]\n","\n","# Convert labels to categorical\n","label_encoder = LabelEncoder()\n","y_train = y_train.astype(str)\n","y_test = y_test.astype(str)\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","num_classes = len(label_encoder.classes_)\n","\n","# Convert tokens to sequences\n","max_sequence_length = 100  # Define the maximum sequence length\n","# Convert tokens to sequences and pad them\n","tokenizer = nltk.tokenize.WordPunctTokenizer()\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_test_sequences = tokenizer.texts_to_sequences(X_test)\n","\n","# Convert tokens to sequences and pad them\n","X_train_sequences = pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post')\n","X_test_sequences = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')\n","\n","# Update the vocabulary size\n","vocabulary_size = len(tokenizer.word_index) + 1\n","\n","# Define the model architecture (LSTM in this example)\n","model = Sequential()\n","model.add(Embedding(input_dim=vocabulary_size, output_dim=100, input_length=max_sequence_length))\n","model.add(LSTM(units=128))\n","model.add(Dense(units=num_classes, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train_sequences, to_categorical(y_train_encoded, num_classes=num_classes), epochs=10, batch_size=32)\n","\n"]},{"cell_type":"code","source":["# Make predictions\n","y_pred_probs = model.predict(X_test_sequences)\n","y_pred = y_pred_probs.argmax(axis=1)\n","\n","# Convert predictions back to original labels\n","y_pred_labels = label_encoder.inverse_transform(y_pred)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred_labels)\n","precision = precision_score(y_test, y_pred_labels, average='weighted')\n","recall = recall_score(y_test, y_pred_labels, average='weighted')\n","f1 = f1_score(y_test, y_pred_labels, average='weighted')\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGwi_sNKwDi4","executionInfo":{"status":"ok","timestamp":1687502375280,"user_tz":-330,"elapsed":9649,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"1fb83017-9392-4fec-8358-7a52e2bd0277"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["155/155 [==============================] - 10s 59ms/step\n","Accuracy: 0.7730482146459552\n","Precision: 0.5976035421672988\n","Recall: 0.7730482146459552\n","F1-score: 0.6740973395206054\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["text = \"وہ اچھا لڑکا ہے\"  # The text you want to classify\n","\n","# Preprocess the text\n","preprocessed_text = preprocess(text)\n","\n","# Tokenize and pad the preprocessed text\n","text_tokens = tokenizer.texts_to_sequences([preprocessed_text])\n","text_tokens_padded = pad_sequences(text_tokens, maxlen=max_sequence_length, padding='post')\n","\n","# Make prediction\n","prediction_probs = model.predict(text_tokens_padded)\n","predicted_class_index = prediction_probs.argmax(axis=1)[0]\n","\n","# Map the predicted class index to the corresponding label\n","predicted_class = label_encoder.inverse_transform([predicted_class_index])[0]\n","\n","# Print the predicted class\n","print(\"Predicted Class:\", predicted_class)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixq1n3Mg5c7B","executionInfo":{"status":"ok","timestamp":1687502606854,"user_tz":-330,"elapsed":404,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"82aa1ecc-9c66-44a7-ddaa-f272cf47fabd"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 50ms/step\n","Predicted Class: Offensive Language\n"]}]},{"cell_type":"code","source":["text = preprocess( \" ایک عورت کے طور پر آپ کو اپنے گھر کی صفائی کے بارے میں شکایت نہیں کرنی چاہیے۔ ایک آدمی ہونے کے ناطے آپ کو ہمیشہ کچرا اٹھانا چاہیے...\")\n"],"metadata":{"id":"JSs-hBMa2_JH","executionInfo":{"status":"ok","timestamp":1687503109006,"user_tz":-330,"elapsed":687,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["sequences = tokenizer.texts_to_sequences([text])"],"metadata":{"id":"w9kgC2cA3XPd","executionInfo":{"status":"ok","timestamp":1687503111337,"user_tz":-330,"elapsed":3,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["sequences = tokenizer.texts_to_sequences([text])"],"metadata":{"id":"CFVYwFL13YWb","executionInfo":{"status":"ok","timestamp":1687503113450,"user_tz":-330,"elapsed":2,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["# Make predictions\n","prediction_probs = model.predict(X_test_sequences)\n","\n","# Convert probabilities to predicted labels\n","y_pred = prediction_probs.argmax(axis=1)\n","\n","predicted_class = label_encoder.inverse_transform(prediction_probs.argmax(axis=1))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AWodbBN3oqE","executionInfo":{"status":"ok","timestamp":1687503125490,"user_tz":-330,"elapsed":10540,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"f636391e-d7ba-47c9-edf1-c2a51717f898"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["155/155 [==============================] - 8s 53ms/step\n"]}]},{"cell_type":"code","source":["# if \"Hate Speech\" in predicted_class:\n","#     print(\"The text is considered hateful.\")\n","# else:\n","#     print(\"The text is not considered hateful.\")\n","if \"Hate Speech\" in predicted_class:\n","    print(\"The text is considered hateful.\")\n","elif \"Offensive Language\" in predicted_class:\n","    print(\"The text is considered offensive.\")\n","elif \"No hate and Offensive Speech\" in predicted_class:\n","    print(\"The text is not considered hateful or offensive.\")\n","else:\n","    print(\"Unknown class.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4h6GM3xW3qUf","executionInfo":{"status":"ok","timestamp":1687503125491,"user_tz":-330,"elapsed":23,"user":{"displayName":"RASHEDIN","userId":"15453162067441304532"}},"outputId":"d39d0d7e-0ce0-43d0-fdb7-8d44b3eb069c"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["The text is considered offensive.\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"oDJxmHQ235iL"},"execution_count":null,"outputs":[]}]}